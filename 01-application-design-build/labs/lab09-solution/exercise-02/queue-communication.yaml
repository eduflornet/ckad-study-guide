apiVersion: v1
kind: ConfigMap
metadata:
  name: queue-scripts
data:
  queue-manager.py: |
    import os
    import json
    import time
    import fcntl
    from datetime import datetime
    
    class FileQueue:
        def __init__(self, queue_file):
            self.queue_file = queue_file
            self.ensure_queue_exists()
        
        def ensure_queue_exists(self):
            if not os.path.exists(self.queue_file):
                with open(self.queue_file, 'w') as f:
                    json.dump([], f)
        
        def put(self, item):
            """Add item to queue"""
            with open(self.queue_file, 'r+') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                queue = json.load(f)
                queue.append(item)
                f.seek(0)
                json.dump(queue, f)
                f.truncate()
        
        def get(self):
            """Get item from queue (FIFO)"""
            with open(self.queue_file, 'r+') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX)
                queue = json.load(f)
                if queue:
                    item = queue.pop(0)
                    f.seek(0)
                    json.dump(queue, f)
                    f.truncate()
                    return item
                return None
        
        def size(self):
            """Get queue size"""
            with open(self.queue_file, 'r') as f:
                queue = json.load(f)
                return len(queue)
  
  producer.py: |
    import sys
    import os
    sys.path.append('/scripts')
    
    # Import the queue manager
    exec(open('/scripts/queue-manager.py').read())
    
    import time
    import random
    from datetime import datetime
    
    def main():
        queue = FileQueue('/shared-queue/tasks.json')
        
        print("Producer starting...")
        task_id = 0
        
        while True:
            task_id += 1
            
            # Create different types of tasks
            task_types = ['process_image', 'send_email', 'generate_report', 'backup_data']
            task_type = random.choice(task_types)
            
            task = {
                'id': task_id,
                'type': task_type,
                'timestamp': datetime.now().isoformat(),
                'data': f'task_data_{task_id}',
                'priority': random.randint(1, 5)
            }
            
            queue.put(task)
            print(f"Produced task {task_id}: {task_type}")
            
            # Variable production rate
            sleep_time = random.uniform(2, 6)
            time.sleep(sleep_time)
    
    if __name__ == "__main__":
        main()
  
  consumer.py: |
    import sys
    import os
    sys.path.append('/scripts')
    
    # Import the queue manager
    exec(open('/scripts/queue-manager.py').read())
    
    import time
    import random
    from datetime import datetime
    
    def process_task(task):
        """Simulate task processing"""
        task_type = task['type']
        task_id = task['id']
        
        print(f"Processing task {task_id}: {task_type}")
        
        # Different processing times for different task types
        processing_times = {
            'process_image': (3, 8),
            'send_email': (1, 3),
            'generate_report': (5, 12),
            'backup_data': (8, 15)
        }
        
        min_time, max_time = processing_times.get(task_type, (2, 5))
        processing_time = random.uniform(min_time, max_time)
        
        time.sleep(processing_time)
        
        # Create result file
        result = {
            'task_id': task_id,
            'type': task_type,
            'status': 'completed',
            'processing_time': processing_time,
            'processed_by': os.getenv('HOSTNAME', 'unknown'),
            'completed_at': datetime.now().isoformat()
        }
        
        # Write result to shared storage
        result_file = f'/shared-results/result_{task_id}.json'
        with open(result_file, 'w') as f:
            import json
            json.dump(result, f, indent=2)
        
        print(f"Completed task {task_id} in {processing_time:.2f}s")
        return result
    
    def main():
        queue = FileQueue('/shared-queue/tasks.json')
        worker_id = os.getenv('HOSTNAME', 'unknown')
        
        print(f"Consumer {worker_id} starting...")
        
        while True:
            task = queue.get()
            
            if task:
                process_task(task)
            else:
                print("No tasks available, waiting...")
                time.sleep(3)
    
    if __name__ == "__main__":
        main()
  
  monitor.py: |
    import sys
    import os
    sys.path.append('/scripts')
    
    import time
    import json
    from datetime import datetime
    
    # Import the queue manager
    exec(open('/scripts/queue-manager.py').read())
    
    def main():
        queue = FileQueue('/shared-queue/tasks.json')
        
        print("Monitor starting...")
        time.sleep(5)  # Let other containers start
        
        while True:
            queue_size = queue.size()
            
            # Count completed tasks
            result_files = []
            if os.path.exists('/shared-results'):
                result_files = [f for f in os.listdir('/shared-results') if f.endswith('.json')]
            
            completed_tasks = len(result_files)
            
            # Calculate processing statistics
            total_processing_time = 0
            task_types = {}
            
            for result_file in result_files:
                try:
                    with open(f'/shared-results/{result_file}', 'r') as f:
                        result = json.load(f)
                        total_processing_time += result.get('processing_time', 0)
                        task_type = result.get('type', 'unknown')
                        task_types[task_type] = task_types.get(task_type, 0) + 1
                except:
                    pass
            
            avg_processing_time = total_processing_time / completed_tasks if completed_tasks > 0 else 0
            
            print(f"=== Queue Monitor Report ===")
            print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"Queue size: {queue_size}")
            print(f"Completed tasks: {completed_tasks}")
            print(f"Average processing time: {avg_processing_time:.2f}s")
            print(f"Task types processed: {task_types}")
            print(f"============================")
            
            time.sleep(10)
    
    if __name__ == "__main__":
        main()
---
apiVersion: v1
kind: Pod
metadata:
  name: queue-communication
spec:
  containers:
  # Task producer
  - name: producer
    image: python:3.11-alpine
    command: ["python", "/scripts/producer.py"]
    volumeMounts:
    - name: queue-scripts
      mountPath: /scripts
    - name: shared-queue
      mountPath: /shared-queue
    - name: shared-results
      mountPath: /shared-results
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
  
  # Task consumer 1
  - name: consumer-1
    image: python:3.11-alpine
    command: ["python", "/scripts/consumer.py"]
    volumeMounts:
    - name: queue-scripts
      mountPath: /scripts
    - name: shared-queue
      mountPath: /shared-queue
    - name: shared-results
      mountPath: /shared-results
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
  
  # Task consumer 2
  - name: consumer-2
    image: python:3.11-alpine
    command: ["python", "/scripts/consumer.py"]
    volumeMounts:
    - name: queue-scripts
      mountPath: /scripts
    - name: shared-queue
      mountPath: /shared-queue
    - name: shared-results
      mountPath: /shared-results
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
  
  # Queue monitor
  - name: monitor
    image: python:3.11-alpine
    command: ["python", "/scripts/monitor.py"]
    volumeMounts:
    - name: queue-scripts
      mountPath: /scripts
    - name: shared-queue
      mountPath: /shared-queue
    - name: shared-results
      mountPath: /shared-results
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
  
  volumes:
  - name: queue-scripts
    configMap:
      name: queue-scripts
      defaultMode: 0755
  - name: shared-queue
    emptyDir: {}
  - name: shared-results
    emptyDir: {}