
# web-api.py

Este c√≥digo implementa una API web en Python usando Flask con un sistema de logging avanzado y simulaci√≥n de errores/carga. Te resumo sus funciones principales:

### üõ†Ô∏è Funcionalidad del c√≥digo
1. Configuraci√≥n de logs en distintos archivos:

access.log ‚Üí registra todas las peticiones y respuestas (m√©todo, ruta, IP, agente, c√≥digo de estado, etc.).

error.log ‚Üí guarda errores de la aplicaci√≥n (fallos simulados, validaciones, excepciones).

application.log ‚Üí registra eventos internos de la aplicaci√≥n (acciones, warnings, tareas de fondo).

2. Endpoints expuestos por la API:

/health ‚Üí chequeo de salud, devuelve estado "healthy".

/users (GET) ‚Üí lista todos los usuarios simulados en memoria.

/users/<id> (GET) ‚Üí obtiene un usuario espec√≠fico.

/users (POST) ‚Üí crea un nuevo usuario, con validaciones y posibilidad de error simulado.

/simulate-load ‚Üí genera carga artificial, m√∫ltiples logs y errores simulados para probar observabilidad.

3. Middleware de logging:

@app.before_request ‚Üí registra cada petici√≥n entrante.

@app.after_request ‚Üí registra cada respuesta, incluyendo un tiempo de procesamiento simulado.

4. Simulaci√≥n de errores y carga:

Probabilidad de error en /users (10%).

Probabilidad de error en creaci√≥n de usuario (15%).

Probabilidad de errores durante la simulaci√≥n de carga (20%).

5. Tareas en segundo plano:

Un hilo (background_logger) genera logs peri√≥dicos cada 30 segundos simulando tareas de mantenimiento (limpieza de cach√©, chequeo de memoria, etc.).

6. Manejo de se√±ales del sistema:

Captura SIGINT y SIGTERM para apagar la aplicaci√≥n de forma ordenada, registrando el evento.

7. Ejecuci√≥n del servidor Flask:

Corre en 0.0.0.0:8080, multihilo, sin modo debug.


### ‚úÖ Beneficios de esta implementaci√≥n
Observabilidad completa: logs separados para accesos, errores y eventos internos.

Resiliencia y pruebas: simula fallos y carga para validar c√≥mo se comporta el sistema bajo estr√©s.

Mantenimiento continuo: tareas en segundo plano que generan m√©tricas y alertas.

Escalabilidad y buenas pr√°cticas: separaci√≥n de responsabilidades entre API, logging y simulaci√≥n.

Preparaci√≥n para despliegue en contenedores/Kubernetes: directorio /logs puede montarse en vol√∫menes compartidos (ideal para sidecar de logging).

En pocas palabras: este c√≥digo es una API de ejemplo con usuarios simulados y un sistema robusto de logging y monitoreo, dise√±ada para probar c√≥mo se comporta una aplicaci√≥n bajo carga y errores, y c√≥mo se integrar√≠a con un patr√≥n Sidecar de observabilidad.

# log-collector.py

Este c√≥digo implementa un recolector de logs en Python que monitorea archivos .log, procesa sus l√≠neas, las guarda en formato JSON y genera estad√≠sticas peri√≥dicas. Aqu√≠ tienes una explicaci√≥n detallada por secciones:

üß† Prop√≥sito general
El script define una clase LogCollector que:

Lee archivos de log en /logs

Procesa cada l√≠nea (como JSON o texto plano)

Guarda los logs procesados en /collected-logs

Genera estad√≠sticas sobre el proceso

Ejecuta todo en hilos paralelos

üß± Componentes principales
1. Configuraci√≥n inicial

```python
logging.basicConfig(...)
logger = logging.getLogger('log-collector')

```

Configura el sistema de logging para registrar eventos con timestamp, nombre, nivel y mensaje.

2. Clase LogCollector
üîß __init__

Define rutas de entrada/salida.
Inicializa estructuras para:
-Posiciones de lectura por archivo (file_positions)
-Logs recolectados (collected_logs)
-Crea el directorio de salida si no existe.

üìñ read_log_file(file_path)
Lee nuevas l√≠neas desde la √∫ltima posici√≥n registrada en un archivo.
Actualiza la posici√≥n para evitar leer l√≠neas duplicadas.

üß™ process_log_line(line, source_file)
Intenta interpretar la l√≠nea como JSON.

Si falla, la trata como texto plano.

A√±ade metadatos como:
-Archivo fuente
-Timestamp de recolecci√≥n
-Nivel de log (por defecto: INFO)

üì• collect_logs()
-Busca archivos .log en /logs.
-Lee nuevas l√≠neas y las procesa.
-Agrupa los logs por archivo fuente.
-Se ejecuta continuamente en un hilo.

üì§ write_collected_logs()
-Cada 5 segundos, escribe los logs recolectados en archivos separados por fuente.
-Los guarda en formato JSON l√≠nea por l√≠nea.
-Limpia los logs ya escritos.

üìä generate_collection_stats()
-Cada 30 segundos, genera estad√≠sticas como:
-N√∫mero de archivos monitoreados
-Posiciones de lectura
-Cantidad de logs pendientes por archivo
-Guarda las estad√≠sticas en collection_stats.json.

‚ñ∂Ô∏è run()
Inicia tres hilos:

-Recolecci√≥n de logs
-Escritura de logs
-Generaci√≥n de estad√≠sticas
-Mantiene el programa vivo hasta que se interrumpe (Ctrl+C).

üèÅ Ejecuci√≥n
python
if __name__ == '__main__':
    collector = LogCollector()
    collector.run()
Crea una instancia del recolector y lo pone en marcha.


